---
title: "MEJOR MODELO"
author: "GRUPO 11"
date: "2025-12-16"
output: html_document
---

# Preparación de los datos

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
```{r}
library(caret)
library(gbm)
library(xgboost)
library(dplyr)
library(pROC)
library(ROSE)
library(smotefamily)
library(DMwR2) 
```

```{r}
mydata <- read.csv("datos_relevantes_Train_Decision3.csv") 

mydata <- mydata %>% select(-ID )%>%
  mutate(across(where(is.character), as.factor)) %>%
  mutate(across(where(~ is.numeric(.) && n_distinct(.) < 20), as.factor))

mydata$Exited <- factor(mydata$Exited)

set.seed(1234)
ind <- sample(1:nrow(mydata), 0.6 * nrow(mydata))

train <- mydata[ind, ]
factor_cols <- names(train)[sapply(train, is.factor)]
test <- mydata[-ind, ]
```

```{r}
# F1 score

F1 <- function(cm) {
p <- cm$byClass["Precision"]
r <- cm$byClass["Recall"]
2*p*r/(p+r)
}

# Ajustar punto de corte

threshold_eval <- function(probs, true){
cortes <- seq(0.1, 0.9, 0.01)
f1s <- recalls <- numeric(length(cortes))

for(i in 1:length(cortes)){
pred <- ifelse(probs > cortes[i], "1","0")
cm <- confusionMatrix(factor(pred, levels=levels(true)), true, positive="1")
f1s[i] <- F1(cm)
recalls[i] <- cm$byClass["Recall"]
}

data.frame(threshold=cortes, F1=f1s, Recall=recalls)
}

```

# XGBoost (SMOTE)

```{r}
xgb_grid <- expand.grid(
  nrounds = c(300, 500),
  max_depth = c(2, 4),
  eta = c(0.01, 0.03),
  gamma = c(0, 0.2),
  colsample_bytree = c(0.7, 0.9),
  min_child_weight = c(1, 5),
  subsample = c(0.7, 0.9))

ctrl_SMOTE <- trainControl(method = "repeatedcv", number = 5, sampling = "smote")
set.seed(123)
modelo_smote3 <-caret::train(Exited ~ .,
                         data = train,
                         method = "xgbTree",
                         trControl = ctrl_SMOTE,tuneGrid=xgb_grid)
probs <- predict(modelo_smote3, newdata = test, type = "prob")[, "1"]

cutoffs <- seq(0.1, 0.9, by = 0.005)
results_smote <- data.frame()

for(cut in cutoffs){
  
  pred <- factor(ifelse(probs > cut, "1", "0"), levels = levels(test$Exited))
  cm <- confusionMatrix(pred, test$Exited, positive = "1")
  
  precision <- cm$byClass["Pos Pred Value"]
  recall <- cm$byClass["Sensitivity"]
  F1 <- 2 * (precision * recall) / (precision + recall)
  
  results_smote <- rbind(
    results_smote,
    data.frame(
      Balance = "SMOTE",
      Cutoff = cut,
      Accuracy = cm$overall["Accuracy"],
      Recall = recall,
      F1 = F1
    )
  )
}

results_smote
```

### Analizar Overfitting

```{r}
probs_train <- predict(modelo_smote3, newdata = train, type = "prob")[, "1"]
pred_train <- factor(ifelse(probs_train > 0.335, "1", "0"), levels = levels(train$Exited))
cm_train<- confusionMatrix(pred_train, train$Exited, positive = "1")
cm_train
probs_test <- predict(modelo_smote3, newdata = test, type = "prob")[, "1"]
pred_test <- factor(ifelse(probs_test > 0.335, "1", "0"), levels = levels(test$Exited))
cm_test <- confusionMatrix(pred_test, test$Exited, positive = "1")
cm_test

library(pROC)
auc_train <- roc(train$Exited, probs_train)$auc
auc_test  <- roc(test$Exited, probs_test)$auc
auc_train
auc_test
```
-Vemos un accuracy muy similar entre train y test, por lo tanto, podemos decir que no hay overfitting.

```{r}
tabla_overfitting <- data.frame(
  Dataset = c("Train", "Test"),
  Accuracy = c(0.7771, 0.7901),
  Kappa = c(0.3832, 0.4195),
  Recall = c(0.5967, 0.6462),
  Specificity = c(0.8243, 0.8263),
  Precision = c(0.4706, 0.4831),
  Balanced_Accuracy = c(0.7105, 0.7363)
)

library(ggplot2)
library(tidyr)

tabla_long <- pivot_longer(
  tabla_overfitting,
  cols = -Dataset,
  names_to = "Metric",
  values_to = "Value"
)

ggplot(tabla_long, aes(x = Metric, y = Value, fill = Dataset)) +
  geom_col(position = "dodge") +
  ylim(0, 1) +
  labs(
    title = "Comparación de métricas: Train vs Test",
    y = "Valor",
    x = "Métrica"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```


# Predicción final

```{r}
# Cargar datos completos
datos_test <- read.csv("datos_relevantes_Test.csv")


# Guardar ID
id_test <- datos_test$ID


# MUY IMPORTANTE 
# Aplicar EXACTAMENTE el mismo preprocesado que train
# 1. Convertir las columnas factor al mismo tipo
for (col in factor_cols) {
  if (col %in% names(datos_test)) {
    datos_test[[col]] <- as.factor(datos_test[[col]])
  }
}

# 2. Convertir todo lo demás a numérico
for (col in setdiff(names(datos_test), factor_cols)) {
  datos_test[[col]] <- as.numeric(datos_test[[col]])
}

# Predicción con XGB
probs_submission <- predict(modelo_smote3, newdata = datos_test, type = "prob")[,"Yes"]
pred_submission <- ifelse(probs_submission > 0.335,"Yes", "No")

# Crear submission
submission <- data.frame(
  ID = id_test,
  Exited = pred_submission
)

submission

#write.csv(submission, "Boosting_XGB_SMOTE_0.335_Decision3.csv", row.names = FALSE)
```

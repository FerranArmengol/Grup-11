---
title: "MEJOR MODELO"
author: "GRUPO 11"
date: "2025-12-16"
output: html_document
---

# Preparación de los datos

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
```{r}
library(caret)
library(gbm)
library(xgboost)
library(dplyr)
library(pROC)
library(ROSE)
library(smotefamily)
library(DMwR2) 
```

```{r}
mydata <- read.csv("datos_relevantes_Train_Decision3.csv") 

mydata <- mydata %>% select(-ID )%>%
  mutate(across(where(is.character), as.factor))

mydata$Exited <- factor(mydata$Exited)

set.seed(1234)
ind <- sample(1:nrow(mydata), 0.6 * nrow(mydata))

train <- mydata[ind, ]
factor_cols <- names(train)[sapply(train, is.factor)]
test <- mydata[-ind, ]
```



# XGBoost (SMOTE)

```{r}
xgb_grid <- expand.grid(
  nrounds = c(600, 800, 1000),
  max_depth = c(2, 3),
  eta = c(0.005, 0.01),
  gamma = c(0, 0.05),
  colsample_bytree = c(0.6, 0.8),
  min_child_weight = c(1, 2),
  subsample = c(0.6, 0.8))

ctrl_SMOTE <- trainControl(method = "repeatedcv", number = 5, sampling = "smote")
set.seed(123)
modelo_smote3 <-caret::train(Exited ~ .,
                         data = train,
                         method = "xgbTree",
                         trControl = ctrl_SMOTE,tuneGrid=xgb_grid)
probs <- predict(modelo_smote3, newdata = test, type = "prob")[, "1"]

cutoffs <- seq(0.1, 0.9, by = 0.005)
results_smote <- data.frame()

for(cut in cutoffs){
  
  pred <- factor(ifelse(probs > cut, "1", "0"), levels = levels(test$Exited))
  cm <- confusionMatrix(pred, test$Exited, positive = "1")
  
  precision <- cm$byClass["Pos Pred Value"]
  recall <- cm$byClass["Sensitivity"]
  F1 <- 2 * (precision * recall) / (precision + recall)
  
  results_smote <- rbind(
    results_smote,
    data.frame(
      Balance = "SMOTE",
      Cutoff = cut,
      Accuracy = cm$overall["Accuracy"],
      Recall = recall,
      F1 = F1
    )
  )
}

results_smote
```
## Curva ROC
```{r}
#install.packages("pROC")  
library(pROC)

p4 <- predict(modelo_smote3, test, type = "prob")
head(p4)

p4 <- p4[, "1"]

r <- multiclass.roc(
  response = test$Exited,
  predictor = p4,
  percent = TRUE)

roc_list <- r[["rocs"]]
r1 <- roc_list[[1]]
```

```{r}
plot.roc(
  r1,
  print.auc = TRUE,
  auc.polygon = TRUE,
  grid = c(0.1, 0.2),
  grid.col = c("green", "red"),
  max.auc.polygon = TRUE,
  auc.polygon.col = "lightblue",
  print.thres = TRUE,
  main = "ROC Curve – XGBoost + SMOTE"
)
```

## Analizar Overfitting


```{r}
probs_train <- predict(modelo_smote3, newdata = train, type = "prob")[, "1"]
pred_train <- factor(ifelse(probs_train > 0.320, "1", "0"), levels = levels(train$Exited))
cm_train<- confusionMatrix(pred_train, train$Exited, positive = "1")
cm_train
probs_test <- predict(modelo_smote3, newdata = test, type = "prob")[, "1"]
pred_test <- factor(ifelse(probs_test >0.320, "1", "0"), levels = levels(test$Exited))
cm_test <- confusionMatrix(pred_test, test$Exited, positive = "1")
cm_test

library(pROC)
auc_train <- roc(train$Exited, probs_train)$auc
auc_test  <- roc(test$Exited, probs_test)$auc
auc_train
auc_test
```
-Vemos un accuracy muy similar entre train y test, por lo tanto, podemos decir que no hay overfitting.

```{r}
tabla_overfitting <- data.frame(
  Dataset = c("Train", "Test"),
  Accuracy = c(0.7851, 0.7923),
  Kappa = c(0.4012, 0.4199),
  Recall = c(0.6061, 0.6372),
  Specificity = c(0.8320, 0.8313),
  Precision = c(0.4855, 0.4869)
)

library(ggplot2)
library(tidyr)

tabla_long <- pivot_longer(
  tabla_overfitting,
  cols = -Dataset,
  names_to = "Metric",
  values_to = "Value"
)

ggplot(tabla_long, aes(x = Metric, y = Value, fill = Dataset)) +
  geom_col(position = "dodge") +
  ylim(0, 1) +
  labs(
    title = "Comparación de métricas: Train vs Test",
    y = "Valor",
    x = "Métrica"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```


# Predicción final

```{r}
# Cargar datos completos
datos_test <- read.csv("datos_relevantes_Test.csv")


# Guardar ID
id_test <- datos_test$ID


# MUY IMPORTANTE 
# Aplicar EXACTAMENTE el mismo preprocesado que train
# 1. Convertir las columnas factor al mismo tipo
for (col in factor_cols) {
  if (col %in% names(datos_test)) {
    datos_test[[col]] <- as.factor(datos_test[[col]])
  }
}

# 2. Convertir todo lo demás a numérico
for (col in setdiff(names(datos_test), factor_cols)) {
  datos_test[[col]] <- as.numeric(datos_test[[col]])
}

# Predicción con XGB
probs_submission <- predict(modelo_smote3, newdata = datos_test, type = "prob")[,"1"]
pred_submission <- ifelse(probs_submission > 0.320,"Yes", "No")

# Crear submission
submission <- data.frame(
  ID = id_test,
  Exited = pred_submission
)

submission

write.csv(submission, "Boosting_XGB_SMOTE_0.320_Decision3.csv", row.names = FALSE)
```

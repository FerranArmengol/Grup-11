---
title: "Untitled"
output: html_document
date: "2025-10-07"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Lectura de los datos
```{r}
#install.packages("dplyr")
library(dplyr)
datos <-read.csv("datos_origen.csv", header = TRUE, sep = ",")
datos$HasCrCard <- as.factor(datos$HasCrCard)
datos$IsActiveMember <- as.factor(datos$IsActiveMember)
datos$SavingsAccountFlag <- as.factor(datos$SavingsAccountFlag)
```

# Little Test
$$
\begin{aligned}
H_0 &: \text{Los datos faltan completamente al azar (MCAR)} \\
H_1 &: \text{Los datos no faltan completamente al azar (no MCAR)}
\end{aligned}
$$

```{r}
naniar::mcar_test(datos)
# Tenemos un p-valor > 0.05, por lo tanto, no tenemos suficiente evidencia estaf√≠stica para decir que los datos que faltan no son de manera aleatoria. Con lo que podemos decir que nuestros datos faltantes sonb MCAR (faltan al azar). 
```

# 4.3 Patrones descriptivos de NA

## 4.3.2 Visulaizaci√≥n de los NA's
```{r}
library(visdat)
library(ggplot2)
library(naniar)
gg_miss_var(datos) + labs(y = "Look at all the missing ones")
```


## 4.3.3 Comparaci√≥n de cada variable con NA's y sin NA's
### Conclusi√≥n: no encontramos grandes cambios en si afecta que una variable este missing en las otras (medias y desviaciones similares).

```{r}
aq_shadow <- bind_shadow(datos)
```


```{r}
# Ejemplo con la variable BALANCE comparada con CreditScore
datos %>%
  bind_shadow() %>%
  group_by(Balance_NA) %>%
  summarise(
    mean_CreditScore = mean(CreditScore, na.rm = TRUE),
    sd_CreditScore = sd(CreditScore, na.rm = TRUE),
    n = n()
  )

```
```{r}
aq_shadow %>%
  ggplot(aes(x = EstimatedSalary, colour = Balance_NA)) +
  geom_density() +
  labs(title = "Distribuci√≥n de salario seg√∫n missing en Balance")

```

```{r}
# Modelo que compara una variable con todas las dem√°s
datos %>%
  bind_shadow() %>%
  group_by(CreditScore_NA) %>%  # Cambia aqu√≠ la variable con missing que quieras analizar
  summarise(across(
    where(is.numeric),
    list(mean = ~mean(.x, na.rm = TRUE),
         sd = ~sd(.x, na.rm = TRUE),
         min = ~min(.x, na.rm = TRUE),
         max = ~max(.x, na.rm = TRUE))
  ))

```


## 4.3.4 
```{r}
prop_miss_case(datos)
prop_miss_var(datos)
miss_case_summary(datos)
miss_case_table(datos)
miss_var_summary(datos)
miss_var_table(datos)

```

# 4.4 imputaci√≥n basica (4.4.3 NO. 4.4.4 solo el grafico)

## Imputaci√≥n con la media (no nos interesa por las var.num.discretas)

```{r}
library(Hmisc)

# Copiar el dataset original
datos_media <- datos

# Vector con las variables num√©ricas a imputar
vars_numericas <- c(
  "X", "Tenure", "NetPromoterScore", "TransactionFrequency",
  "Age", "ComplaintsCount", "EstimatedSalary", "AvgTransactionAmount",
  "DigitalEngagementScore", "ID", "CreditScore", "Balance",
  "NumOfProducts", "Exited"
)

# Imputar con la media en cada variable num√©rica
for (var in vars_numericas) {
  datos_media[[var]] <- with(datos_media, Hmisc::impute(datos_media[[var]], mean))
}
```

## Imputaci√≥n con la mediana (no tendremos ese problema)

```{r}
# Crear una copia del dataset original
datos_mediana <- datos

# Seleccionar autom√°ticamente las variables num√©ricas
vars_numericas <- names(datos_mediana)[sapply(datos_mediana, is.numeric)]

# Imputar los NA con la mediana de cada variable
for (v in vars_numericas) {
  mediana <- median(datos_mediana[[v]], na.rm = TRUE)
  datos_mediana[[v]][is.na(datos_mediana[[v]])] <- mediana
}

# Diagn√≥stico simple de las variables imputadas
summary(datos_mediana)


```

```{r}
library(dplyr)
library(tidyr)
library(ggplot2)

# Crear un dataframe con las tres versiones de la variable
df_long <- data.frame(
  Original = datos$Balance,
  Media = datos_media$Balance,
  Mediana = datos_mediana$Balance
) %>%
  pivot_longer(cols = everything(),
               names_to = "Tipo",
               values_to = "Valor")

# Graficar densidades
ggplot(df_long, aes(x = Valor, fill = Tipo)) +
  geom_density(alpha = 0.3) +
  labs(title = "Distribuci√≥n de 'Balance' original vs imputaciones",
       x = "Balance",
       y = "Densidad") +
  theme_minimal() +
  scale_fill_manual(values = c("blue", "red", "green"))
  
```


# Imputaci√≥n para todas las variables

# MICE
```{r}
datos_MICE<-datos
datos_MICE$Surname <- NULL
datos_MICE$HasCrCard <- as.factor(datos_MICE$HasCrCard)
datos_MICE$IsActiveMember <- as.factor(datos_MICE$IsActiveMember)
datos_MICE$SavingsAccountFlag <- as.factor(datos_MICE$SavingsAccountFlag)
datos_MICE$Gender  <- as.factor(datos_MICE$Gender)
datos_MICE$EducationLevel    <- as.factor(datos_MICE$EducationLevel)
datos_MICE$CustomerSegment  <- as.factor(datos_MICE$CustomerSegment)
datos_MICE$MaritalStatus  <- as.factor(datos_MICE$MaritalStatus)
datos_MICE$LoanStatus  <- as.factor(datos_MICE$LoanStatus)
datos_MICE$Geography   <- as.factor(datos_MICE$Geography)
```

```{r}
#install.packages("mice")
library(mice)
set.seed(123)

```


```{r}
# ======================================================
# üß† IMPUTACI√ìN MICE SEPARADA (NUM√âRICAS / CATEG√ìRICAS)
# + EVALUACI√ìN DE LAS 5 IMPUTACIONES + VISUALIZACI√ìN
# ======================================================

# 1Ô∏è‚É£ Cargar librer√≠as
library(naniar)
library(mice)
library(dplyr)
library(ggplot2)

# 2Ô∏è‚É£ Preparar el dataset
# Aseg√∫rate de tener tu dataset cargado como 'datos_MICE'
# datos_MICE <- df  # si tu dataset original se llama df

# 3Ô∏è‚É£ Separar variables
num_vars <- datos_MICE[, sapply(datos_MICE, is.numeric) & names(datos_MICE) != "ID"]
cat_vars <- datos_MICE[, sapply(datos_MICE, is.factor)]

# ======================================================
# üß© IMPUTACI√ìN DE VARIABLES NUM√âRICAS
# ======================================================

set.seed(123)
mice_num <- mice(num_vars, m = 5, method = "pmm", maxit = 5, printFlag = FALSE)
num_list <- lapply(1:5, function(i) complete(mice_num, i))

# ======================================================
# üß© IMPUTACI√ìN DE VARIABLES CATEG√ìRICAS
# ======================================================

meth_cat <- make.method(cat_vars)
meth_cat[] <- "polyreg"

set.seed(123)
mice_cat <- mice(cat_vars, m = 5, method = meth_cat, maxit = 5, printFlag = FALSE)
cat_list <- lapply(1:5, function(i) complete(mice_cat, i))

# ======================================================
# üßÆ EVALUACI√ìN DE IMPUTACIONES
# ======================================================

# --- Evaluaci√≥n de num√©ricas ---
eval_num <- data.frame(Imputation = 1:5, MeanDiff = NA, SdDiff = NA)

for (i in 1:5) {
  imp_df <- num_list[[i]]
  
  diffs <- c()
  sds <- c()
  for (v in names(imp_df)) {
    obs_mean <- mean(num_vars[[v]], na.rm = TRUE)
    imp_mean <- mean(imp_df[[v]], na.rm = TRUE)
    diffs <- c(diffs, abs(obs_mean - imp_mean))
    
    obs_sd <- sd(num_vars[[v]], na.rm = TRUE)
    imp_sd <- sd(imp_df[[v]], na.rm = TRUE)
    sds <- c(sds, abs(obs_sd - imp_sd))
  }
  
  eval_num$MeanDiff[i] <- mean(diffs, na.rm = TRUE)
  eval_num$SdDiff[i] <- mean(sds, na.rm = TRUE)
}

# --- Evaluaci√≥n de categ√≥ricas ---
eval_cat <- data.frame(Imputation = 1:5, ChiSum = NA)

for (i in 1:5) {
  imp_df <- cat_list[[i]]
  chi_values <- c()
  
  for (v in names(imp_df)) {
    obs_tab <- table(na.omit(cat_vars[[v]]))
    imp_tab <- table(imp_df[[v]])
    all_levels <- union(names(obs_tab), names(imp_tab))
    obs_tab <- obs_tab[match(all_levels, names(obs_tab), nomatch = 0)]
    imp_tab <- imp_tab[match(all_levels, names(imp_tab), nomatch = 0)]
    obs_tab[is.na(obs_tab)] <- 0
    imp_tab[is.na(imp_tab)] <- 0
    
    suppressWarnings({
      chi <- tryCatch(chisq.test(rbind(obs_tab, imp_tab))$statistic, error = function(e) NA)
    })
    chi_values <- c(chi_values, chi)
  }
  eval_cat$ChiSum[i] <- mean(chi_values, na.rm = TRUE)
}

# --- Combinar evaluaciones ---
eval_results <- merge(eval_num, eval_cat, by = "Imputation")

# Normalizar m√©tricas y calcular score total
eval_results <- eval_results %>%
  mutate(
    ScoreNum = scale(MeanDiff) + scale(SdDiff),
    ScoreCat = scale(ChiSum),
    TotalScore = ScoreNum + ScoreCat
  ) %>%
  arrange(TotalScore)

print(eval_results)

best_imp <- eval_results$Imputation[1]
cat("üëâ La mejor imputaci√≥n combinada (num√©rica + categ√≥rica) es la n√∫mero:", best_imp, "\n")

# ======================================================
# ‚úÖ CREAR EL DATASET FINAL CON ESA IMPUTACI√ìN
# ======================================================

num_imputed_best <- num_list[[best_imp]]
cat_imputed_best <- cat_list[[best_imp]]
df_imputed <- cbind(ID = datos_MICE$ID, num_imputed_best, cat_imputed_best)

# Verificar que no haya NA
colSums(is.na(df_imputed))

# ======================================================
# üìä VISUALIZACI√ìN DE RESULTADOS
# ======================================================
library(ggplot2)
ggplot(eval_results, aes(x = factor(Imputation), y = TotalScore, fill = TotalScore)) +
  geom_col(width = 0.6) +
  geom_text(aes(label = round(TotalScore, 2)), vjust = -0.5, size = 4) +
  scale_fill_gradient(low = "skyblue", high = "navy") +
  labs(
    title = "Comparaci√≥n de imputaciones MICE (num√©ricas + categ√≥ricas)",
    subtitle = "Menor TotalScore = Imputaci√≥n m√°s coherente",
    x = "N√∫mero de imputaci√≥n",
    y = "Puntuaci√≥n total (TotalScore)",
    fill = "TotalScore"
  ) +
  theme_minimal(base_size = 14)

# ======================================================
# üíæ (Opcional) Guardar dataset final
# ======================================================

# Asegurarte de que la columna ID es num√©rica
df_imputed$ID <- as.numeric(df_imputed$ID)

# Identificar cu√°ntos NA hay
num_na <- sum(is.na(df_imputed$ID))

# Generar los IDs posibles para imputar (3001 a 10000)
ids_posibles <- 3001:10000

# Eliminar los IDs que ya existen (para no repetir)
ids_disponibles <- setdiff(ids_posibles, df_imputed$ID)

# Comprobar que hay suficientes IDs disponibles
if (num_na > length(ids_disponibles)) {
  stop("No hay suficientes IDs disponibles entre 3001 y 10000 para imputar todos los NA.")
}

# Asignar los nuevos IDs aleatoriamente a los NA
set.seed(123)  # opcional, para reproducibilidad
df_imputed$ID[is.na(df_imputed$ID)] <- sample(ids_disponibles, num_na, replace = FALSE)

write.csv(df_imputed, "datos_missing.csv", row.names = FALSE)
```

#KNN

```{r}
# Instalar si no lo tienes
#install.packages("VIM")
#library(VIM)


#knn_imputed <- kNN(datos_MICE, k = 5)
#knn_imputed <- knn_imputed[, !grepl("_imp$", names(knn_imputed))]
#summary(knn_imputed)

```

## Comparaci√≥n gr√°fica: vemos que el MICE es mejor
```{r}
#newBD <- data.frame(real = datos[, "Balance"], imputed = knn_imputed[, "Balance"])
#df_long <- newBD %>%
  #pivot_longer(cols = everything(), names_to = "Variable", values_to = "Valor")

#ggplot(df_long, aes(x = Valor, fill = Variable)) +
 # geom_density(alpha = 0.3) +  # Transparencia para mejor visualizaci√≥n
 # labs(title = "Densidad de las tres variables",
  #     x = "Valor",
  #     y = "Densidad") +
 # theme_minimal() +
 # scale_fill_manual(values = c("blue", "red"))
```


```{r}
newBD <- data.frame(real = datos[, "Balance"], imputed = df_imputed[, "Balance"])
df_long <- newBD %>%
  pivot_longer(cols = everything(), names_to = "Variable", values_to = "Valor")

ggplot(df_long, aes(x = Valor, fill = Variable)) +
  geom_density(alpha = 0.3) +  # Transparencia para mejor visualizaci√≥n
  labs(title = "Densidad de las tres variables",
       x = "Valor",
       y = "Densidad") +
  theme_minimal() +
  scale_fill_manual(values = c("blue", "red"))
```

## Selecci√≥n de variables
```{r}
## 1Ô∏è‚É£ Eliminaci√≥n de variables con baja varianza (Filter)
library(caret)
datos_missing <-read.csv("datos_missing.csv", header = TRUE, sep = ",")
nzv <- nearZeroVar(datos_missing, saveMetrics = TRUE)
nzv

# Eliminar variables con varianza cercana a cero
datos_fs <- datos_missing[, !nzv$nzv]
cat("Variables eliminadas por baja varianza:\n")
print(rownames(nzv[nzv$nzv == TRUE, ]))

## An√°lisis de correlaci√≥n entre variables (Filter)
library(corrplot)

# Usamos solo variables num√©ricas
num_vars <- datos_fs[, sapply(datos_fs, is.numeric)]
cor_matrix <- cor(num_vars, use = "complete.obs")

# Visualizar matriz de correlaci√≥n
corrplot(cor_matrix, method = "color", tl.cex = 0.6)

# Eliminar variables con correlaci√≥n > 0.90
high_cor <- findCorrelation(cor_matrix, cutoff = 0.90)
cat("Variables eliminadas por alta correlaci√≥n:\n")
print(colnames(num_vars)[high_cor])

num_vars_reduced <- num_vars[, -high_cor]

## Selecci√≥n basada en importancia del modelo (Wrapper / Embedding)
library(randomForest)

# Convertimos Exited a factor si es necesario
datos_fs$Exited <- as.factor(datos_fs$Exited)

# Entrenar modelo para obtener importancia
set.seed(123)
rf_model <- randomForest(Exited ~ ., data = datos_fs, importance = TRUE, ntree = 200)

# Importancia de variables
varImpPlot(rf_model)

# Extraer variables m√°s importantes
importance_values <- importance(rf_model)
important_vars <- rownames(importance_values)[order(importance_values[, 1], decreasing = TRUE)]

cat("Variables importantes seg√∫n Random Forest:\n")
print(important_vars)

## Dataset final con las principales variables
top_vars <- important_vars[1:10]   # Seleccionamos top 10 variables
datos_final <- datos_fs[, top_vars]
```

---
title: "Untitled"
output: html_document
date: "2025-10-07"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Lectura de los datos
```{r}
#install.packages("dplyr")
library(dplyr)
datos <-read.csv("datos_origen.csv", header = TRUE, sep = ",")
datos$HasCrCard <- as.factor(datos$HasCrCard)
datos$IsActiveMember <- as.factor(datos$IsActiveMember)
datos$SavingsAccountFlag <- as.factor(datos$SavingsAccountFlag)
```

# Little Test
$$
\begin{aligned}
H_0 &: \text{Los datos faltan completamente al azar (MCAR)} \\
H_1 &: \text{Los datos no faltan completamente al azar (no MCAR)}
\end{aligned}
$$

```{r}
naniar::mcar_test(datos)
# Tenemos un p-valor > 0.05, por lo tanto, no tenemos suficiente evidencia estafística para decir que los datos que faltan no son de manera aleatoria. Con lo que podemos decir que nuestros datos faltantes sonb MCAR (faltan al azar). 
```

# 4.3 Patrones descriptivos de NA

## 4.3.2 Visulaización de los NA's
```{r}
library(visdat)
library(ggplot2)
library(naniar)
gg_miss_var(datos) + labs(y = "Look at all the missing ones")
```


## 4.3.3 Comparación de cada variable con NA's y sin NA's
### Conclusión: no encontramos grandes cambios en si afecta que una variable este missing en las otras (medias y desviaciones similares).

```{r}
aq_shadow <- bind_shadow(datos)
```


```{r}
# Ejemplo con la variable BALANCE comparada con CreditScore
datos %>%
  bind_shadow() %>%
  group_by(Balance_NA) %>%
  summarise(
    mean_CreditScore = mean(CreditScore, na.rm = TRUE),
    sd_CreditScore = sd(CreditScore, na.rm = TRUE),
    n = n()
  )

```
```{r}
aq_shadow %>%
  ggplot(aes(x = EstimatedSalary, colour = Balance_NA)) +
  geom_density() +
  labs(title = "Distribución de salario según missing en Balance")

```

```{r}
# Modelo que compara una variable con todas las demás
datos %>%
  bind_shadow() %>%
  group_by(CreditScore_NA) %>%  # Cambia aquí la variable con missing que quieras analizar
  summarise(across(
    where(is.numeric),
    list(mean = ~mean(.x, na.rm = TRUE),
         sd = ~sd(.x, na.rm = TRUE),
         min = ~min(.x, na.rm = TRUE),
         max = ~max(.x, na.rm = TRUE))
  ))

```


## 4.3.4 
```{r}
prop_miss_case(datos)
prop_miss_var(datos)
miss_case_summary(datos)
miss_case_table(datos)
miss_var_summary(datos)
miss_var_table(datos)

```

# 4.4 imputación basica (4.4.3 NO. 4.4.4 solo el grafico)

## Imputación con la media (no nos interesa por las var.num.discretas)

```{r}
library(Hmisc)

# Copiar el dataset original
datos_media <- datos

# Vector con las variables numéricas a imputar
vars_numericas <- c(
  "X", "Tenure", "NetPromoterScore", "TransactionFrequency",
  "Age", "ComplaintsCount", "EstimatedSalary", "AvgTransactionAmount",
  "DigitalEngagementScore", "ID", "CreditScore", "Balance",
  "NumOfProducts", "Exited"
)

# Imputar con la media en cada variable numérica
for (var in vars_numericas) {
  datos_media[[var]] <- with(datos_media, Hmisc::impute(datos_media[[var]], mean))
}
```

## Imputación con la mediana (no tendremos ese problema)

```{r}
# Crear una copia del dataset original
datos_mediana <- datos

# Seleccionar automáticamente las variables numéricas
vars_numericas <- names(datos_mediana)[sapply(datos_mediana, is.numeric)]

# Imputar los NA con la mediana de cada variable
for (v in vars_numericas) {
  mediana <- median(datos_mediana[[v]], na.rm = TRUE)
  datos_mediana[[v]][is.na(datos_mediana[[v]])] <- mediana
}

# Diagnóstico simple de las variables imputadas
summary(datos_mediana)


```

```{r}
library(dplyr)
library(tidyr)
library(ggplot2)

# Crear un dataframe con las tres versiones de la variable
df_long <- data.frame(
  Original = datos$Balance,
  Media = datos_media$Balance,
  Mediana = datos_mediana$Balance
) %>%
  pivot_longer(cols = everything(),
               names_to = "Tipo",
               values_to = "Valor")

# Graficar densidades
ggplot(df_long, aes(x = Valor, fill = Tipo)) +
  geom_density(alpha = 0.3) +
  labs(title = "Distribución de 'Balance' original vs imputaciones",
       x = "Balance",
       y = "Densidad") +
  theme_minimal() +
  scale_fill_manual(values = c("blue", "red", "green"))
  
```


# Imputación para todas las variables

# MICE
```{r}
datos_MICE<-datos
datos_MICE$Surname <- NULL
datos_MICE$X<-NULL
datos_MICE$HasCrCard <- as.factor(datos_MICE$HasCrCard)
datos_MICE$IsActiveMember <- as.factor(datos_MICE$IsActiveMember)
datos_MICE$SavingsAccountFlag <- as.factor(datos_MICE$SavingsAccountFlag)
datos_MICE$Gender  <- as.factor(datos_MICE$Gender)
datos_MICE$EducationLevel    <- as.factor(datos_MICE$EducationLevel)
datos_MICE$CustomerSegment  <- as.factor(datos_MICE$CustomerSegment)
datos_MICE$MaritalStatus  <- as.factor(datos_MICE$MaritalStatus)
datos_MICE$LoanStatus  <- as.factor(datos_MICE$LoanStatus)
datos_MICE$Geography   <- as.factor(datos_MICE$Geography)

```

```{r}
#install.packages("mice")
library(mice)
set.seed(123)

```

# IMPUTACIÓN MICE SEPARADA (NUMÉRICAS / CATEGÓRICAS)
```{r}

# Cargar librerías
library(naniar)
library(mice)
library(dplyr)
library(ggplot2)

# Preparar el dataset
# Asegúrate de tener tu dataset cargado como 'datos_MICE'
# datos_MICE <- df  # si tu dataset original se llama df

#  Separar variables
num_vars <- datos_MICE[, sapply(datos_MICE, is.numeric) & names(datos_MICE) != "ID" & names(datos_MICE) != "Exited"]
cat_vars <- datos_MICE[, sapply(datos_MICE, is.factor)]

# IMPUTACIÓN DE VARIABLES NUMÉRICAS

set.seed(123)
mice_num <- mice(num_vars, m = 5, method = "pmm", maxit = 5, printFlag = FALSE)
num_list <- lapply(1:5, function(i) complete(mice_num, i))

# IMPUTACIÓN DE VARIABLES CATEGÓRICAS

meth_cat <- make.method(cat_vars)
meth_cat[] <- "polyreg"

set.seed(123)
mice_cat <- mice(cat_vars, m = 5, method = meth_cat, maxit = 5, printFlag = FALSE)
cat_list <- lapply(1:5, function(i) complete(mice_cat, i))

# EVALUACIÓN DE IMPUTACIONES

# --- Evaluación de numéricas ---
eval_num <- data.frame(Imputation = 1:5, MeanDiff = NA, SdDiff = NA)

for (i in 1:5) {
  imp_df <- num_list[[i]]
  
  diffs <- c()
  sds <- c()
  for (v in names(imp_df)) {
    obs_mean <- mean(num_vars[[v]], na.rm = TRUE)
    imp_mean <- mean(imp_df[[v]], na.rm = TRUE)
    diffs <- c(diffs, abs(obs_mean - imp_mean))
    
    obs_sd <- sd(num_vars[[v]], na.rm = TRUE)
    imp_sd <- sd(imp_df[[v]], na.rm = TRUE)
    sds <- c(sds, abs(obs_sd - imp_sd))
  }
  
  eval_num$MeanDiff[i] <- mean(diffs, na.rm = TRUE)
  eval_num$SdDiff[i] <- mean(sds, na.rm = TRUE)
}

# --- Evaluación de categóricas ---
eval_cat <- data.frame(Imputation = 1:5, ChiSum = NA)

for (i in 1:5) {
  imp_df <- cat_list[[i]]
  chi_values <- c()
  
  for (v in names(imp_df)) {
    obs_tab <- table(na.omit(cat_vars[[v]]))
    imp_tab <- table(imp_df[[v]])
    all_levels <- union(names(obs_tab), names(imp_tab))
    obs_tab <- obs_tab[match(all_levels, names(obs_tab), nomatch = 0)]
    imp_tab <- imp_tab[match(all_levels, names(imp_tab), nomatch = 0)]
    obs_tab[is.na(obs_tab)] <- 0
    imp_tab[is.na(imp_tab)] <- 0
    
    suppressWarnings({
      chi <- tryCatch(chisq.test(rbind(obs_tab, imp_tab))$statistic, error = function(e) NA)
    })
    chi_values <- c(chi_values, chi)
  }
  eval_cat$ChiSum[i] <- mean(chi_values, na.rm = TRUE)
}

# --- Combinar evaluaciones ---
eval_results <- merge(eval_num, eval_cat, by = "Imputation")

# Normalizar métricas y calcular score total
eval_results <- eval_results %>%
  mutate(
    ScoreNum = scale(MeanDiff) + scale(SdDiff),
    ScoreCat = scale(ChiSum),
    TotalScore = ScoreNum + ScoreCat
  ) %>%
  arrange(TotalScore)

print(eval_results)

best_imp <- eval_results$Imputation[1]
best_imp

# CREAR EL DATASET FINAL CON ESA IMPUTACIÓN

num_imputed_best <- num_list[[best_imp]]
cat_imputed_best <- cat_list[[best_imp]]
df_imputed <- cbind(ID = datos_MICE$ID, num_imputed_best, cat_imputed_best)

# Verificar que no haya NA

colSums(is.na(df_imputed))

# VISUALIZACIÓN DE RESULTADOS
library(ggplot2)
ggplot(eval_results, aes(x = factor(Imputation), y = TotalScore, fill = TotalScore)) +
  geom_col(width = 0.6) +
  geom_text(aes(label = round(TotalScore, 2)), vjust = -0.5, size = 4) +
  scale_fill_gradient(low = "skyblue", high = "navy") +
  labs(
    title = "Comparación de imputaciones MICE (numéricas + categóricas)",
    subtitle = "Menor TotalScore = Imputación más coherente",
    x = "Número de imputación",
    y = "Puntuación total (TotalScore)",
    fill = "TotalScore"
  ) +
  theme_minimal(base_size = 14)

# Guardar dataset final

# Asegurarte de que la columna ID es numérica
df_imputed$ID <- as.numeric(df_imputed$ID)

# Identificar cuántos NA hay
num_na <- sum(is.na(df_imputed$ID))

# Generar los IDs posibles para imputar (3001 a 10000)
ids_posibles <- 3001:10000

# Eliminar los IDs que ya existen (para no repetir)
ids_disponibles <- setdiff(ids_posibles, df_imputed$ID)

# Comprobar que hay suficientes IDs disponibles
if (num_na > length(ids_disponibles)) {
  stop("No hay suficientes IDs disponibles entre 3001 y 10000 para imputar todos los NA.")
}

# Asignar los nuevos IDs aleatoriamente a los NA
set.seed(123)  
df_imputed$ID[is.na(df_imputed$ID)] <- sample(ids_disponibles, num_na, replace = FALSE)
df_imputed<-cbind(df_imputed,Exited=datos_MICE$Exited)
write.csv(df_imputed, "datos_missing.csv", row.names = FALSE)
```

#KNN

```{r}
# Instalar si no lo tienes
#install.packages("VIM")
#library(VIM)


#knn_imputed <- kNN(datos_MICE, k = 5)
#knn_imputed <- knn_imputed[, !grepl("_imp$", names(knn_imputed))]
#summary(knn_imputed)

```

## Comparación gráfica: vemos que el MICE es mejor
```{r}
#newBD <- data.frame(real = datos[, "Balance"], imputed = knn_imputed[, "Balance"])
#df_long <- newBD %>%
  #pivot_longer(cols = everything(), names_to = "Variable", values_to = "Valor")

#ggplot(df_long, aes(x = Valor, fill = Variable)) +
 # geom_density(alpha = 0.3) +  # Transparencia para mejor visualización
 # labs(title = "Densidad de las tres variables",
  #     x = "Valor",
  #     y = "Densidad") +
 # theme_minimal() +
 # scale_fill_manual(values = c("blue", "red"))
```


```{r}
newBD <- data.frame(real = datos[, "Balance"], imputed = df_imputed[, "Balance"])
df_long <- newBD %>%
  pivot_longer(cols = everything(), names_to = "Variable", values_to = "Valor")

ggplot(df_long, aes(x = Valor, fill = Variable)) +
  geom_density(alpha = 0.3) +  # Transparencia para mejor visualización
  labs(title = "Densidad de las tres variables",
       x = "Valor",
       y = "Densidad") +
  theme_minimal() +
  scale_fill_manual(values = c("blue", "red"))
```

## Selección de variables
```{r}

library(caret)
library(corrplot)
library(randomForest)
library(dplyr)
library(tidyr)

# Leer los datos
datos_missing <- read.csv("datos_missing.csv", header = TRUE, sep = ",")
```
#Selección de las variables
```{r}
numeric_cols <- sapply(datos_missing, is.numeric)
datos_num <- datos_missing[, numeric_cols]

# Guardar variable objetivo y eliminarla de los numéricos
if ("Exited" %in% names(datos_num)) {
  target <- datos_num$Exited
  datos_num <- datos_num[, names(datos_num) != "Exited", drop = FALSE]
} else {
  target <- datos_missing$Exited
}

# Varianza nula 
nzv <- nearZeroVar(datos_num, saveMetrics = TRUE)
datos_nv <- datos_num[, !nzv$nzv]
cat("Variables eliminadas por baja varianza:", sum(nzv$nzv), "\n")
```
```{r}
# Correlación
cor_matrix <- cor(datos_nv, use = "complete.obs")
high_cor <- findCorrelation(cor_matrix, cutoff = 0.9)
if (length(high_cor) > 0) {
  cat(" Eliminadas por alta correlación:", length(high_cor), "\n")
  datos_corr <- datos_nv[, -high_cor, drop = FALSE]
} else {
  datos_corr <- datos_nv
  cat(" No hay correlaciones altas.\n")
}

library("corrplot")

matriz_corr <- cor(datos_nv[, 1:15])
corrplot(matriz_corr, method = "circle")
```

```{r}
# Combinaciones lineales
datos_corr_na <- drop_na(datos_corr)
combos <- findLinearCombos(datos_corr_na)
if (!is.null(combos$remove)) {
  datos_lineales <- datos_corr_na[, -combos$remove, drop = FALSE]
  cat(" Eliminadas por combinaciones lineales:", length(combos$remove), "\n")
} else {
  datos_lineales <- datos_corr_na
  cat(" No se encontraron combinaciones lineales.\n")
}
```



